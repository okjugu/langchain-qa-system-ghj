{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5356a4c-5171-4ade-93e7-21aa874a6e65",
   "metadata": {},
   "source": [
    "# 构建一个检索增强生成（RAG）应用程序：第一部分\n",
    "介绍 RAG 并讲解一个最小的实现\n",
    "\n",
    "这里我们专注于非结构化数据的问答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa85787-36c9-42e2-ad08-4c09bc5a30ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8fd46051-6540-4e1e-a564-8505d7df0f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      " ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d2c0bd-eb7e-42dd-984e-fbfd19dce8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for DeepSeek:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"DEEPSEEK_API_KEY\"):\n",
    "  os.environ[\"DEEPSEEK_API_KEY\"] = getpass.getpass(\"Enter API key for DeepSeek: \")\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"deepseek-chat\", model_provider=\"deepseek\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "98d9ac28-752a-4049-904d-bd7e48f90014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter API key for Alibaba Cloud DashScope:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# 设置阿里云API密钥（替换OpenAI的）\n",
    "if not os.environ.get(\"DASHSCOPE_API_KEY\"):\n",
    "    os.environ[\"DASHSCOPE_API_KEY\"] = getpass.getpass(\"Enter API key for Alibaba Cloud DashScope: \")\n",
    "\n",
    "# 导入阿里云的嵌入模型\n",
    "from langchain.embeddings import DashScopeEmbeddings\n",
    "\n",
    "# 初始化阿里云嵌入模型\n",
    "embeddings = DashScopeEmbeddings(model=\"text-embedding-v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "164ac6bd-dcc3-4463-8055-96fde9a1915b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8bf674-6028-4e99-be25-f098b9199c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total characters: 43047\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "# Only keep post title, headers, and content from the full HTML.\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"post-title\", \"post-header\", \"post-content\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "assert len(docs) == 1\n",
    "print(f\"Total characters: {len(docs[0].page_content)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96da1e7d-746e-47f7-9c28-cdaa4621df9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "      LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\n",
      "Agent System Overview#\n",
      "In\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88f276cf-8047-4daf-ae06-2ebb092fca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split blog post into 63 sub-documents.\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,  # chunk size (characters)\n",
    "    chunk_overlap=200,  # chunk overlap (characters)\n",
    "    add_start_index=True,  # track index in original document\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "print(f\"Split blog post into {len(all_splits)} sub-documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "39c08ab1-eeca-4805-a184-765ae3361d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d14c729f-134f-44a8-9940-810b4e7e5bcd', '92502ab0-c1e5-4062-b6b3-c5fad747b56b', 'ca23e4e0-f364-44ea-98b7-e600b6939d31']\n"
     ]
    }
   ],
   "source": [
    "document_ids = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "print(document_ids[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "614244f2-bf7d-45dc-9d70-1073c53e71f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: (question goes here) \n",
      "Context: (context goes here) \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "\n",
    "# N.B. for non-US LangSmith endpoints, you may need to specify\n",
    "# api_url=\"https://api.smith.langchain.com\" in hub.pull.\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "assert len(example_messages) == 1\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc224117-60d1-44a7-ab09-9b22cd83fb95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "from typing_extensions import List, TypedDict\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e6ae37f-2fd7-42dc-a762-5cb4de4860fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(state: State):\n",
    "    retrieved_docs = vector_store.similarity_search(state[\"question\"])\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a86ac76-e86b-487c-ae57-32f4e0057beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, StateGraph\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7348378b-afc9-4c95-a665-d51d82a8850b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bab7160f-e396-459e-9079-dc459ddc5d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context: [Document(id='ca23e4e0-f364-44ea-98b7-e600b6939d31', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='42d51549-020c-4a5b-909c-3f55fa66d1f3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='822cc988-8935-4c30-b697-7978c60f3d59', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17352}, page_content='Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='9dc55a25-d82e-48d0-ba59-e49d50dede68', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17734}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.')]\n",
      "\n",
      "\n",
      "Answer: Task Decomposition is a technique used to break down complex tasks into smaller, more manageable steps. It can be achieved by instructing a model to \"think step by step\" or by using task-specific instructions and human input. Methods like Chain of Thought and Tree of Thoughts are common approaches for task decomposition.\n"
     ]
    }
   ],
   "source": [
    "result = graph.invoke({\"question\": \"What is Task Decomposition?\"})\n",
    "\n",
    "print(f\"Context: {result['context']}\\n\\n\")\n",
    "print(f\"Answer: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dde08439-1d69-421d-885c-09c09101424e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'retrieve': {'context': [Document(id='ca23e4e0-f364-44ea-98b7-e600b6939d31', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 1638}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.'), Document(id='42d51549-020c-4a5b-909c-3f55fa66d1f3', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 2578}, page_content='Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.\\nAnother quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#'), Document(id='822cc988-8935-4c30-b697-7978c60f3d59', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17352}, page_content='Illustration of how HuggingGPT works. (Image source: Shen et al. 2023)\\n\\nThe system comprises of 4 stages:\\n(1) Task planning: LLM works as the brain and parses the user requests into multiple tasks. There are four attributes associated with each task: task type, ID, dependencies, and arguments. They use few-shot examples to guide LLM to do task parsing and planning.\\nInstruction:'), Document(id='9dc55a25-d82e-48d0-ba59-e49d50dede68', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 17734}, page_content='The AI assistant can parse user input to several tasks: [{\"task\": task, \"id\", task_id, \"dep\": dependency_task_ids, \"args\": {\"text\": text, \"image\": URL, \"audio\": URL, \"video\": URL}}]. The \"dep\" field denotes the id of the previous task which generates a new resource that the current task relies on. A special tag \"-task_id\" refers to the generated text image, audio and video in the dependency task with id as task_id. The task MUST be selected from the following options: {{ Available Task List }}. There is a logical relationship between tasks, please note their order. If the user input can\\'t be parsed, you need to reply empty JSON. Here are several cases for your reference: {{ Demonstrations }}. The chat history is recorded as {{ Chat History }}. From this chat history, you can find the path of the user-mentioned resources for your task planning.')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Task decomposition is a technique for breaking down complex tasks into smaller, more manageable steps. It can be achieved through methods like Chain of Thought prompting, which instructs a model to reason step-by-step, or by using task-specific instructions and human input. Another approach involves outsourcing the planning to an external classical planner.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream( # 流式传输\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"updates\"\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00712403-fbf1-4051-a620-46f2a7a8c79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Task| decomposition| is| a| technique| used| by| AI| agents| to| break| down| complex| tasks| into| smaller|,| more| manageable| steps|.| It| can| be| achieved| through| methods| like| Chain| of| Thought| prompting|,| which| instruct|s| a| model| to| \"|think| step| by| step|,\"| or| by| using| task|-specific| instructions| and| human| input|.| This| process| helps| in| planning| and| interpreting| the| model|'s| approach| to| solving| a| problem|.||"
     ]
    }
   ],
   "source": [
    "for message, metadata in graph.stream( # 流失token\n",
    "    {\"question\": \"What is Task Decomposition?\"}, stream_mode=\"messages\"\n",
    "):\n",
    "    print(message.content, end=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab68a97b-bef6-42ff-afe3-8c681459a8b3",
   "metadata": {},
   "source": [
    "对于异步，和之前的类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66ed4306-2c49-4b49-9ccf-e66662264e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
       " 'start_index': 8,\n",
       " 'section': 'beginning'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查询分析 利用模型从原始用户输入中转换或构建优化的搜索查询。\n",
    "# 我们可以轻松地将查询分析步骤整合到我们的应用程序中。为了说明目的，让我们向向量存储中的文档添加一些元数据。\n",
    "# 我们将向文档添加一些（人为设计的）部分，以便稍后进行过滤。\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "all_splits[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b1689cd-9578-4974-9dc9-916750e9c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用一个简单的 InMemoryVectorStore，因为我们将使用它的一些特定功能（即，元数据过滤）\n",
    "\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df55c84c-2373-4bdd-abfa-c73df2ae2ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 让我们定义搜索查询的 schema。我们将为此目的使用 结构化输出。\n",
    "# 在这里，我们定义一个查询包含一个字符串查询和一个文档部分（可以是“开头”、“中间”或“结尾”），\n",
    "from typing import Literal\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b81a6ffb-6e5e-45cf-b597-27a0d2ca138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 向 LangGraph 应用程序添加一个步骤，以从用户的原始输入中生成查询\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e138233a-46de-4370-8d32-cc6dfae622b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'analyze_query': {'query': {'query': 'Task Decomposition', 'section': 'end'}}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'retrieve': {'context': [Document(id='22bfc847-d5c2-44f8-95a2-2119045e8bc4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 31986, 'section': 'end'}, page_content='},\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{There are 10 levels in total. The main character is a plumber named Mario, who can walk and jump. It is a classical platform game just like Super Mario. The main character moves from left to right, trying to get to the destination, where there are many obstacles and attacks from enemies in the process.}}\\\\n\\\\nIs anything else unclear? If yes, only answer in the form:\\\\n{remaining unclear areas} remaining questions.\\\\n{Next question}\\\\nIf everything is sufficiently clear, only answer \\\\\"Nothing more to clarify.\\\\\".\"\\n  },\\n  {\\n    \"role\": \"assistant\",\\n    \"content\": \"Remaining unclear areas: 2 remaining questions.\\\\nCan you provide more information about how the MVC components are split into separate files?\"\\n  },\\n  {\\n    \"role\": \"user\",\\n    \"content\": \"{{Make your own assumptions and state them explicitly before starting}}\"\\n  }\\n]\\nThen after these clarification, the agent moved into the code writing mode with a different system message.'), Document(id='e71a7380-2974-4a67-a6a8-75560644a3a4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 38621, 'section': 'end'}, page_content='are imported by that file, and so on.\\\\nFollow a language and framework appropriate best practice file naming convention.\\\\nMake sure that files contain all imports, types etc. The code should be fully functional. Make sure that code in different files are compatible with each other.\\\\nBefore you finish, double check that all parts of the architecture is present in the files.\\\\n\"'), Document(id='87bca4fd-198c-4436-b17d-94139bde70c4', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 39137, 'section': 'end'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.'), Document(id='9d128e6c-c6f7-4a63-a67c-84896dda2e2e', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'start_index': 35043, 'section': 'end'}, page_content='\"content\": \"You will get instructions for code to write.\\\\nYou will write a very long answer. Make sure that every detail of the architecture is, in the end, implemented as code.\\\\nMake sure that every detail of the architecture is, in the end, implemented as code.\\\\n\\\\nThink step by step and reason yourself to the right decisions to make sure we get it right.\\\\nYou will first lay out the names of the core classes, functions, methods that will be necessary, as well as a quick comment on their purpose.\\\\n\\\\nThen you will output the content of each file including ALL code.\\\\nEach file must strictly follow a markdown code block format, where the following tokens must be replaced such that\\\\nFILENAME is the lowercase file name including the file extension,\\\\nLANG is the markup code block language for the code\\'s language, and CODE is the code:\\\\n\\\\nFILENAME\\\\n```LANG\\\\nCODE\\\\n```\\\\n\\\\nYou will start with the \\\\\"entrypoint\\\\\" file, then go to the ones that are imported by that file, and so on.\\\\nPlease')]}}\n",
      "\n",
      "----------------\n",
      "\n",
      "{'generate': {'answer': 'Based on the provided context, the end of the post does not specifically mention Task Decomposition. It discusses challenges in long-term planning and how LLMs struggle to adjust plans when faced with errors.'}}\n",
      "\n",
      "----------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"What does the end of the post say about Task Decomposition?\"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d999249-9034-48ad-afd9-2bb12eae9bea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain Env_1017",
   "language": "python",
   "name": "langchain_env_1017"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
